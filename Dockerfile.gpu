FROM nvidia/cuda:11.6.2-cudnn8-runtime-ubuntu20.04

ENV PYTHONUNBUFFERED TRUE

RUN apt-get update \
    && apt-get install --no-install-recommends -y \
    ca-certificates \
    g++ \
    python3-dev \
    python3-distutils \
    python3-venv \
    openjdk-11-jre-headless \
    curl \
    wget \
    && rm -rf /var/lib/apt/lists/* \
    && cd /tmp \
    && curl -O https://bootstrap.pypa.io/get-pip.py \
    && python3 get-pip.py \
    && rm get-pip.py

RUN python3 -m venv /home/venv

ENV PATH="/home/venv/bin:$PATH"

RUN update-alternatives --install /usr/bin/python python /usr/bin/python3 1
RUN update-alternatives --install /usr/local/bin/pip pip /usr/local/bin/pip3 1

RUN pip install -U pip setuptools

#for CUDA  install 
RUN export USE_CUDA=1
ARG CUDA=1
RUN if [ $CUDA==1 ]; then \ 
        pip install nvgpu; \
    fi

#CUDA version
RUN pip install --no-cache-dir torch torchvision torchserve --extra-index-url https://download.pytorch.org/whl/cu116
RUN pip install --no-cache-dir PyYAML captum

#add user for execute the commands 
RUN useradd -m model-server

COPY dockerd-entrypoint.sh /usr/local/bin/dockerd-entrypoint.sh
COPY config.properties /home/model-server/config.properties

#create two folder for models and workflow 
RUN mkdir /home/model-server/model-store && mkdir /home/model-server/wf-store
#copy all required models and pipelines inside docker 
COPY model-store /home/model-server/model-store
COPY wf-store /home/model-server/wf-store

#giving rights for execute for entrypoint
RUN chmod +x /usr/local/bin/dockerd-entrypoint.sh \
    && mkdir -p /home/model-server/tmp \
    && chown -R model-server /home/model-server \
    && chown -R model-server /home/venv

#GIVING rights to execute 
RUN chown -R model-server /home/model-server/model-store
RUN chown -R model-server /home/model-server/wf-store

EXPOSE 8080 8081 8082

USER model-server
WORKDIR /home/model-server
ENV TEMP=/home/model-server/tmp
ENTRYPOINT ["/usr/local/bin/dockerd-entrypoint.sh"]
CMD ["serve", "curl"]  